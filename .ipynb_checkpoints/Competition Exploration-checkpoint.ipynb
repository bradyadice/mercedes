{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as sm\n",
    "import sys\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LassoLars\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"/home/sir/Documents/mercedes/test.csv\") # test has no y value, y comes from train split\n",
    "train = pd.read_csv(\"/home/sir/Documents/mercedes/train.csv\")\n",
    "\n",
    "uniq = {}\n",
    "#dummyvariables\n",
    "for colname in ['X0', 'X1', 'X2','X3','X4','X5','X6','X8']:\n",
    "    uniq[colname] = train[colname].unique()\n",
    "for colname in ['X0', 'X1', 'X2','X3','X4','X5','X6','X8']:\n",
    "    train[colname] = train[colname].apply(lambda x: np.where(uniq[colname] == x)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>y</th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X8</th>\n",
       "      <th>...</th>\n",
       "      <th>X375</th>\n",
       "      <th>X376</th>\n",
       "      <th>X377</th>\n",
       "      <th>X378</th>\n",
       "      <th>X379</th>\n",
       "      <th>X380</th>\n",
       "      <th>X382</th>\n",
       "      <th>X383</th>\n",
       "      <th>X384</th>\n",
       "      <th>X385</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>130.81</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>88.53</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>76.26</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>80.62</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>78.02</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 378 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID       y  X0  X1  X2  X3  X4  X5  X6  X8  ...   X375  X376  X377  X378  \\\n",
       "0   0  130.81   0   0   0   0   0   0   0   0  ...      0     0     1     0   \n",
       "1   6   88.53   0   1   1   1   0   1   1   0  ...      1     0     0     0   \n",
       "2   7   76.26   1   2   2   2   0   2   0   1  ...      0     0     0     0   \n",
       "3   9   80.62   1   1   2   3   0   2   1   2  ...      0     0     0     0   \n",
       "4  13   78.02   1   0   2   3   0   3   2   3  ...      0     0     0     0   \n",
       "\n",
       "   X379  X380  X382  X383  X384  X385  \n",
       "0     0     0     0     0     0     0  \n",
       "1     0     0     0     0     0     0  \n",
       "2     0     0     1     0     0     0  \n",
       "3     0     0     0     0     0     0  \n",
       "4     0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 378 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.59196992348988053"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.asarray(train)\n",
    "X,y = data[:, 2:], data[:, 1]\n",
    "lr = LinearRegression()\n",
    "lr.fit(X, y)\n",
    "lr.coef_ # which factors are most importante\n",
    "lr.intercept_\n",
    "lr.score(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=4.682e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 1.054e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.706e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 1.054e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.706e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/least_angle.py:377: RuntimeWarning: overflow encountered in true_divide\n",
      "  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny))\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/least_angle.py:381: RuntimeWarning: overflow encountered in true_divide\n",
      "  g2 = arrayfuncs.min_pos((C + Cov) / (AA + corr_eq_dir + tiny))\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.446e-02, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.309e-02, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.309e-02, with an active set of 14 regressors, and the smallest cholesky pivot element being 1.054e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.222e-02, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.54101214531137609"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.asarray(train)\n",
    "X,y = data[:, 2:], data[:, 1]\n",
    "lr = LassoLars(alpha=0.01)\n",
    "lr.fit(X, y)\n",
    "lr.coef_ # which factors are most importante\n",
    "lr.intercept_\n",
    "lr.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.asarray(train)\n",
    "X,y = data[:, 2:], data[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62448863253826614"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'n_estimators': 500, 'max_depth': 4, 'min_samples_split': 2,\n",
    "          'learning_rate': 0.01, 'loss': 'ls'}\n",
    "gbr = GradientBoostingRegressor(**params)\n",
    "gbr.fit(X,y)\n",
    "gbr.score(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My shit: regression\n",
      "0.584974938306"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import sys\n",
    "print(\"My shit: regression\")\n",
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    xgb_model = xgb.XGBRegressor().fit(X[train_index],y[train_index])\n",
    "    predictions = xgb_model.predict(X[test_index])\n",
    "    actuals = y[test_index]\n",
    "    sys.stdout.write('\\r' + str(r2_score(actuals, predictions)))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "0s - loss: 4279.9394 - r2_keras: -2.7216e+01\n",
      "Epoch 2/70\n",
      "0s - loss: 1058.2866 - r2_keras: -6.7822e+00\n",
      "Epoch 3/70\n",
      "0s - loss: 158.1037 - r2_keras: 0.0340\n",
      "Epoch 4/70\n",
      "0s - loss: 156.6225 - r2_keras: 0.0306\n",
      "Epoch 5/70\n",
      "0s - loss: 154.7191 - r2_keras: 0.0492\n",
      "Epoch 6/70\n",
      "0s - loss: 151.5514 - r2_keras: 0.0749\n",
      "Epoch 7/70\n",
      "0s - loss: 147.0456 - r2_keras: 0.0984\n",
      "Epoch 8/70\n",
      "0s - loss: 138.3143 - r2_keras: 0.1600\n",
      "Epoch 9/70\n",
      "0s - loss: 128.2175 - r2_keras: 0.2357\n",
      "Epoch 10/70\n",
      "0s - loss: 111.2782 - r2_keras: 0.3454\n",
      "Epoch 11/70\n",
      "0s - loss: 98.8073 - r2_keras: 0.4295\n",
      "Epoch 12/70\n",
      "0s - loss: 91.5757 - r2_keras: 0.4735\n",
      "Epoch 13/70\n",
      "0s - loss: 89.3969 - r2_keras: 0.4867\n",
      "Epoch 14/70\n",
      "0s - loss: 86.7267 - r2_keras: 0.5082\n",
      "Epoch 15/70\n",
      "0s - loss: 86.1251 - r2_keras: 0.5090\n",
      "Epoch 16/70\n",
      "0s - loss: 84.2935 - r2_keras: 0.5195\n",
      "Epoch 17/70\n",
      "0s - loss: 84.2246 - r2_keras: 0.5266\n",
      "Epoch 18/70\n",
      "0s - loss: 84.3528 - r2_keras: 0.5246\n",
      "Epoch 19/70\n",
      "0s - loss: 84.4079 - r2_keras: 0.5225\n",
      "Epoch 20/70\n",
      "0s - loss: 82.4104 - r2_keras: 0.5283\n",
      "Epoch 21/70\n",
      "0s - loss: 85.1066 - r2_keras: 0.5210\n",
      "Epoch 22/70\n",
      "0s - loss: 82.8489 - r2_keras: 0.5283\n",
      "Epoch 23/70\n",
      "0s - loss: 83.8815 - r2_keras: 0.5093\n",
      "Epoch 24/70\n",
      "0s - loss: 83.4079 - r2_keras: 0.5230\n",
      "Epoch 25/70\n",
      "0s - loss: 81.3780 - r2_keras: 0.5413\n",
      "Epoch 26/70\n",
      "0s - loss: 81.8696 - r2_keras: 0.5332\n",
      "Epoch 27/70\n",
      "0s - loss: 81.8722 - r2_keras: 0.5338\n",
      "Epoch 28/70\n",
      "0s - loss: 83.1473 - r2_keras: 0.5329\n",
      "Epoch 29/70\n",
      "0s - loss: 81.3436 - r2_keras: 0.5361\n",
      "Epoch 30/70\n",
      "0s - loss: 80.5047 - r2_keras: 0.5426\n",
      "Epoch 31/70\n",
      "0s - loss: 82.9520 - r2_keras: 0.5212\n",
      "Epoch 32/70\n",
      "0s - loss: 81.1081 - r2_keras: 0.5454\n",
      "Epoch 33/70\n",
      "0s - loss: 83.0605 - r2_keras: 0.5237\n",
      "Epoch 34/70\n",
      "0s - loss: 81.5560 - r2_keras: 0.5358\n",
      "Epoch 35/70\n",
      "0s - loss: 80.3369 - r2_keras: 0.5489\n",
      "Epoch 36/70\n",
      "0s - loss: 80.3129 - r2_keras: 0.5336\n",
      "Epoch 37/70\n",
      "0s - loss: 83.5944 - r2_keras: 0.5136\n",
      "Epoch 38/70\n",
      "0s - loss: 79.3949 - r2_keras: 0.5551\n",
      "Epoch 39/70\n",
      "0s - loss: 80.5531 - r2_keras: 0.5425\n",
      "Epoch 40/70\n",
      "0s - loss: 81.4353 - r2_keras: 0.5338\n",
      "Epoch 41/70\n",
      "0s - loss: 81.1277 - r2_keras: 0.5364\n",
      "Epoch 42/70\n",
      "0s - loss: 78.7123 - r2_keras: 0.5503\n",
      "Epoch 43/70\n",
      "0s - loss: 78.1240 - r2_keras: 0.5613\n",
      "Epoch 44/70\n",
      "0s - loss: 78.6394 - r2_keras: 0.5545\n",
      "Epoch 45/70\n",
      "0s - loss: 78.7041 - r2_keras: 0.5527\n",
      "Epoch 46/70\n",
      "0s - loss: 78.2875 - r2_keras: 0.5546\n",
      "Epoch 47/70\n",
      "0s - loss: 80.7009 - r2_keras: 0.5429\n",
      "Epoch 48/70\n",
      "0s - loss: 77.3318 - r2_keras: 0.5618\n",
      "Epoch 49/70\n",
      "0s - loss: 78.2429 - r2_keras: 0.5549\n",
      "Epoch 50/70\n",
      "0s - loss: 78.2568 - r2_keras: 0.5597\n",
      "Epoch 51/70\n",
      "0s - loss: 78.5502 - r2_keras: 0.5583\n",
      "Epoch 52/70\n",
      "0s - loss: 77.3923 - r2_keras: 0.5619\n",
      "Epoch 53/70\n",
      "0s - loss: 79.8841 - r2_keras: 0.5399\n",
      "Epoch 54/70\n",
      "0s - loss: 80.4458 - r2_keras: 0.5415\n",
      "Epoch 55/70\n",
      "0s - loss: 76.1975 - r2_keras: 0.5751\n",
      "Epoch 56/70\n",
      "0s - loss: 76.7346 - r2_keras: 0.5659\n",
      "Epoch 57/70\n",
      "0s - loss: 77.1852 - r2_keras: 0.5661\n",
      "Epoch 58/70\n",
      "0s - loss: 76.8851 - r2_keras: 0.5618\n",
      "Epoch 59/70\n",
      "0s - loss: 77.1091 - r2_keras: 0.5685\n",
      "Epoch 60/70\n",
      "0s - loss: 78.1458 - r2_keras: 0.5557\n",
      "Epoch 61/70\n",
      "0s - loss: 76.6682 - r2_keras: 0.5645\n",
      "Epoch 62/70\n",
      "0s - loss: 78.4538 - r2_keras: 0.5526\n",
      "Epoch 63/70\n",
      "0s - loss: 78.0951 - r2_keras: 0.5590\n",
      "Epoch 64/70\n",
      "0s - loss: 75.9529 - r2_keras: 0.5712\n",
      "Epoch 65/70\n",
      "0s - loss: 74.8127 - r2_keras: 0.5873\n",
      "Epoch 66/70\n",
      "0s - loss: 75.1065 - r2_keras: 0.5779\n",
      "Epoch 67/70\n",
      "0s - loss: 75.5481 - r2_keras: 0.5764\n",
      "Epoch 68/70\n",
      "0s - loss: 77.2747 - r2_keras: 0.5585\n",
      "Epoch 69/70\n",
      "0s - loss: 75.9052 - r2_keras: 0.5725\n",
      "Epoch 70/70\n",
      "0s - loss: 76.7667 - r2_keras: 0.5571\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding,Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "%matplotlib inline\n",
    "from keras import backend as K\n",
    "\n",
    "def r2_keras(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
    "\n",
    "#Red data from csv file for training and validation data\n",
    "X_train, y_train, X_test, y_test = X[:int(len(X)*.8)], y[:int(len(y)*.8)], X[int(len(X)*.8):], y[int(len(y)*.8):]\n",
    "\n",
    "\n",
    "\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Embedding(10, 64, input_length=376))\n",
    "model.add(Dense(20, activation=\"selu\", kernel_initializer=\"uniform\", input_shape=(376,)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation=\"linear\", kernel_initializer=\"uniform\"))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='mse', optimizer='adam', metrics=[r2_keras])\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit(X_train, y_train, epochs=70,verbose=2)\n",
    "\n",
    "# Calculate predictions\n",
    "PredTestSet = model.predict(X_train)\n",
    "PredValSet = model.predict(X_test)\n",
    "\n",
    "# Save predictions\n",
    "numpy.savetxt(\"trainresults.csv\", PredTestSet, delimiter=\",\")\n",
    "numpy.savetxt(\"valresults.csv\", PredValSet, delimiter=\",\")\n",
    "                                                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate predictions\n",
    "PredTestSet = model.predict(X_train)\n",
    "PredValSet = model.predict()\n",
    "\n",
    "# Save predictions\n",
    "numpy.savetxt(\"trainresults.csv\", PredTestSet, delimiter=\",\")\n",
    "numpy.savetxt(\"valresults.csv\", PredValSet, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 32/842 [>.............................] - ETA: 1s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[49.831389909685363, 0.61561767817109891]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.asarray(train)\n",
    "X,y = data[:, 2:], data[:, 1]\n",
    "X_train, y_train, X_test, y_test = X[:int(len(X)*.8)], y[:int(len(y)*.8)], X[int(len(X)*.8):], y[int(len(y)*.8):]\n",
    "model.evaluate(x=X_test, y=y_test,verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'r2_keras']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(filepath='/home/sir/Documents/mercedes/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: h5py in /home/sir/.local/lib/python3.5/site-packages\r\n",
      "Requirement already satisfied: six in /home/sir/.local/lib/python3.5/site-packages (from h5py)\r\n",
      "Requirement already satisfied: numpy>=1.7 in /home/sir/.local/lib/python3.5/site-packages (from h5py)\r\n"
     ]
    }
   ],
   "source": [
    "!pip3 install h5py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "`save_model` requires h5py.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-a62c3a14c438>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'filepath=/home/sir/Documents/mercedes/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/sir/.local/lib/python3.5/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m   2551\u001b[0m         \"\"\"\n\u001b[1;32m   2552\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2553\u001b[0;31m         \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sir/.local/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mh5py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`save_model` requires h5py.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_json_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: `save_model` requires h5py."
     ]
    }
   ],
   "source": [
    "model.save('filepath=/home/sir/Documents/mercedes/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mse'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make prediction file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"/home/sir/Documents/mercedes/test.csv\") # test has no y value, y comes from train split\n",
    "\n",
    "uniq = {}\n",
    "#dummyvariables\n",
    "for colname in ['X0', 'X1', 'X2','X3','X4','X5','X6','X8']:\n",
    "    uniq[colname] = test[colname].unique()\n",
    "for colname in ['X0', 'X1', 'X2','X3','X4','X5','X6','X8' ]:\n",
    "    test[colname] = test[colname].apply(lambda x: np.where(uniq[colname] == x)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X8</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X375</th>\n",
       "      <th>X376</th>\n",
       "      <th>X377</th>\n",
       "      <th>X378</th>\n",
       "      <th>X379</th>\n",
       "      <th>X380</th>\n",
       "      <th>X382</th>\n",
       "      <th>X383</th>\n",
       "      <th>X384</th>\n",
       "      <th>X385</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 377 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  X0  X1  X2  X3  X4  X5  X6  X8  X10  ...   X375  X376  X377  X378  \\\n",
       "0   1   0   0   0   0   0   0   0   0    0  ...      0     0     0     1   \n",
       "1   2   1   1   1   1   0   1   1   1    0  ...      0     0     1     0   \n",
       "2   3   0   0   2   0   0   2   2   2    0  ...      0     0     0     1   \n",
       "3   4   0   2   0   0   0   3   3   3    0  ...      0     0     0     1   \n",
       "4   5   2   3   2   2   0   4   4   4    0  ...      1     0     0     0   \n",
       "\n",
       "   X379  X380  X382  X383  X384  X385  \n",
       "0     0     0     0     0     0     0  \n",
       "1     0     0     0     0     0     0  \n",
       "2     0     0     0     0     0     0  \n",
       "3     0     0     0     0     0     0  \n",
       "4     0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 377 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1,    2,    3, ..., 8413, 8414, 8416])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.asarray(test)\n",
    "X,ids = data[:, 1:], data[:, 0]\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4209"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    79.537277\n",
       "2    90.373596\n",
       "3    78.071587\n",
       "4    76.783966\n",
       "5    95.152115\n",
       "dtype: float32"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = pd.Series(predictions[:,0])\n",
    "pred.index = ids\n",
    "pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.to_csv('/home/sir/Documents/mercedes/results.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4209"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
